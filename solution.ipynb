{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba110bf0-0874-4704-807d-38b67efdd511",
   "metadata": {},
   "source": [
    "- Ğ­Ñ‚Ğ¾Ñ‚ Ğ½Ğ¾ÑƒÑ‚Ğ±ÑƒĞº ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¡ĞŸĞĞœ-Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² (Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ğ°Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ).\n",
    "- Ğ’ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ roc_auc, Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾ Ñ Ñ‚Ğ°ĞºĞ¶Ğµ Ñ€ĞµÑˆĞ¸Ğ»Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° precision, Ñ‚.Ğº. Ğ² Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğµ Ğ²Ğ°Ğ¶Ğ½Ğ° Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ false positives Ğ´Ğ»Ñ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾ Ğ½Ğµ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ°Ğ¶Ğ½Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğº ÑĞ¿Ğ°Ğ¼\n",
    "\n",
    "  \n",
    "*Ğ‘Ñ‹Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ñ‹ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹*:\n",
    "- ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ sklearn Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ñ‡ĞºĞ¸. ĞĞ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞµĞµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ SVM, RandomForest, ExtraTreesClassifier. ĞĞ´Ğ½Ğ°ĞºĞ¾ roc_auc Ğ½Ğµ Ğ¿Ñ€ĞµĞ²Ñ‹ÑĞ¸Ğ» 0.93\n",
    "- Ğ”Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½ GridSearch Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾ roc_auc ÑÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ½Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ»ÑÑ\n",
    "- Ğ¡Ñ‚ĞµĞºĞ¸Ğ½Ğ³ Ğ¸Ğ· Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ğ¿ĞµÑ€ĞµÑ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ²Ñ‹ÑˆĞµ, roc_auc ÑÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ½Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ»ÑÑ\n",
    "- ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸-Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ° roberta Ğ¸Ğ· Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ hugginface. Ğ—Ğ´ĞµÑÑŒ Ğ´Ğ°Ğ¶Ğµ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğµ Ğ¿Ğ¾Ğ½Ğ°Ğ´Ğ¾Ğ±Ğ¸Ğ»Ğ¾ÑÑŒ, Ñ‚.Ğº. Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑƒĞ¶Ğµ Ğ±Ñ‹Ğ»Ğ° Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ğ½Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ° Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ roc_auc=0.99. Ğ­Ñ‚Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68649cd8-1528-4fe3-b222-844a8b540689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞº\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c337a-0066-4a68-aa2c-c2987360dbd2",
   "metadata": {},
   "source": [
    "### 1. ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a417415d-db09-408d-8763-bb23fa062371",
   "metadata": {},
   "source": [
    "**Ğ’Ñ‹Ğ²Ğ¾Ğ´Ñ‹**\n",
    "1. Ğ’ Ñ‚Ñ€ĞµĞ¹Ğ½ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ 16278 ÑÑ‚Ñ€Ğ¾Ğº Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ\n",
    "2. Ğ•ÑÑ‚ÑŒ 2 ĞºĞ»Ğ°ÑÑĞ° - spam Ğ¸ ham (Ğ½ÑƒĞ¶Ğ½Ğ° ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ñ‡Ğ¸ÑĞ»Ğ°Ğ¼Ğ¸ 0 Ğ¸Ğ»Ğ¸ 1)\n",
    "3. ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ½ĞµÑ‚\n",
    "4. Ğ•ÑÑ‚ÑŒ Ğ´Ğ¸ÑĞ±Ğ°Ğ»Ğ°Ğ½Ñ ĞºĞ»Ğ°ÑÑĞ¾Ğ² (Ğ¿Ñ€ĞµĞ¾Ğ±Ğ»Ğ°Ğ´Ğ°ĞµÑ‚ ĞºĞ»Ğ°ÑÑ 0). Ğ¡Ğ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾, Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ»ÑƒÑ‡ÑˆĞµ Ğ±Ñ€Ğ°Ñ‚ÑŒ ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºÑƒ\n",
    "5. Ğ•ÑÑ‚ÑŒ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68a1f1f-f721-4ac2-82d2-139f251bb663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ğŸ‘€ kuch b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text\n",
       "0           ham  make sure alex knows his birthday is over in f...\n",
       "1           ham  a resume for john lavorato thanks vince i will...\n",
       "2          spam  plzz visit my website moviesgodml to get all m...\n",
       "3          spam  urgent your mobile number has been awarded wit...\n",
       "4           ham  overview of hr associates analyst project per ...\n",
       "...         ...                                                ...\n",
       "16273      spam  if you are interested in binary options tradin...\n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...\n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...\n",
       "16276       ham  insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ğŸ‘€ kuch b...\n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...\n",
       "\n",
       "[16278 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°\n",
    "train_df = pd.read_csv('train_spam.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6ea38b-4588-46dc-a091-9d02e23c31ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16278 entries, 0 to 16277\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text_type  16278 non-null  object\n",
      " 1   text       16278 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 254.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea63af2-ecf1-4742-a8b6-c2e03e86ab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_type    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ¿ÑƒÑÑ‚Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da015d7-3881-46a9-a400-e3f75b56695e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€\n",
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe98d6c3-7deb-4112-96c2-655ab93dde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²\n",
    "train_df = train_df.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bed64ec-e16f-4274-8aee-9655e4592acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of 0 : 70.4370812073523\n",
      "percentage of 1 : 29.56291879264769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/9dxsk7gs7fxg8nmzktwnpj0w0000gn/T/ipykernel_9321/1985025021.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  percentage_0 = (values[0] /total) * 100\n",
      "/var/folders/1g/9dxsk7gs7fxg8nmzktwnpj0w0000gn/T/ipykernel_9321/1985025021.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  percentage_1 = (values[1]/ total) *100\n"
     ]
    }
   ],
   "source": [
    "# ÑĞ¾Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğµ ĞºĞ»Ğ°ÑÑĞ¾Ğ²\n",
    "values = train_df['text_type'].value_counts()\n",
    "total = values.sum()\n",
    "\n",
    "percentage_0 = (values[0] /total) * 100\n",
    "percentage_1 = (values[1]/ total) *100\n",
    "\n",
    "print('percentage of 0 :' ,percentage_0)\n",
    "print('percentage of 1 :' ,percentage_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "87672055-6d2b-4144-a118-56508f053526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ¾Ğ»-Ğ²Ğµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ², ÑĞ»Ğ¾Ğ² Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹\n",
    "train_df['num_characters'] = train_df['text'].apply(len)\n",
    "train_df['num_words'] = train_df['text'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "train_df['num_sentence'] = train_df['text'].apply(lambda x: len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720333ad-80b7-4624-bac1-8fcef7076821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16267.000000</td>\n",
       "      <td>16267.000000</td>\n",
       "      <td>16267.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>310.468986</td>\n",
       "      <td>57.141944</td>\n",
       "      <td>1.062212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>287.887904</td>\n",
       "      <td>52.134400</td>\n",
       "      <td>0.376116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>157.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>639.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_characters     num_words  num_sentence\n",
       "count    16267.000000  16267.000000  16267.000000\n",
       "mean       310.468986     57.141944      1.062212\n",
       "std        287.887904     52.134400      0.376116\n",
       "min          1.000000      1.000000      1.000000\n",
       "25%         60.000000     12.000000      1.000000\n",
       "50%        157.000000     31.000000      1.000000\n",
       "75%        639.000000    114.000000      1.000000\n",
       "max        800.000000    207.000000     12.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['num_characters', 'num_words', 'num_sentence']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f9efa4a-337f-480c-b3c9-6af3371cf535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text  num_characters  num_words  num_sentence\n",
       "text_type                                               \n",
       "ham         142             142        142           142\n",
       "spam          3               3          3             3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ¿Ğ¾ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ñƒ Ğ²Ğ¸Ğ´Ğ½Ğ¾, Ñ‡Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ ÑÑ‚Ñ€Ğ¾ĞºĞ¸, Ğ´Ğ»Ğ¸Ğ½Ğ° ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… = 1 ÑĞ»Ğ¾Ğ²Ğ¾. Ğ¡ĞºĞ¾Ñ€ĞµĞµ Ğ²ÑĞµĞ³Ğ¾ Ğ¾Ğ½Ğ¸ Ğ½Ğµ Ğ½ĞµÑÑƒÑ‚ Ñ†ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸, Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¸Ñ… Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑƒĞ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ\n",
    "train_df[train_df['num_words'] < 2].groupby('text_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b010570d-8810-4476-b995-251102b11d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ham</td>\n",
       "      <td>urgent</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>ham</td>\n",
       "      <td>fast</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>ham</td>\n",
       "      <td>freemasonry</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>ham</td>\n",
       "      <td>logs</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>ham</td>\n",
       "      <td>landed</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15738</th>\n",
       "      <td>ham</td>\n",
       "      <td>txt</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15780</th>\n",
       "      <td>ham</td>\n",
       "      <td>staffsciencenusedusgphyhcmkteachingpc1323</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15890</th>\n",
       "      <td>ham</td>\n",
       "      <td>derpherp</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16067</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16230</th>\n",
       "      <td>ham</td>\n",
       "      <td>sax</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                       text  num_characters  \\\n",
       "76          ham                                     urgent               6   \n",
       "149         ham                                       fast               4   \n",
       "170         ham                                freemasonry              11   \n",
       "233         ham                                       logs               4   \n",
       "331         ham                                     landed               6   \n",
       "...         ...                                        ...             ...   \n",
       "15738       ham                                        txt               3   \n",
       "15780       ham  staffsciencenusedusgphyhcmkteachingpc1323              41   \n",
       "15890       ham                                   derpherp               8   \n",
       "16067       ham                                         ok               2   \n",
       "16230       ham                                        sax               3   \n",
       "\n",
       "       num_words  num_sentence  \n",
       "76             1             1  \n",
       "149            1             1  \n",
       "170            1             1  \n",
       "233            1             1  \n",
       "331            1             1  \n",
       "...          ...           ...  \n",
       "15738          1             1  \n",
       "15780          1             1  \n",
       "15890          1             1  \n",
       "16067          1             1  \n",
       "16230          1             1  \n",
       "\n",
       "[145 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice_to_drop = train_df[train_df['num_words'] < 2].index\n",
    "train_df[train_df['num_words'] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e43dc-df61-45df-8291-b6fe08467e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… ÑÑ‚Ñ€Ğ¾Ğº\n",
    "train_df = train_df.drop(indice_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d3de8-2dc2-4adf-b2fb-bb875684a0f6",
   "metadata": {},
   "source": [
    "### 2. ĞŸÑ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a46b53b-ee1b-4055-b8f2-d0f4e7b3d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irinba/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/irinba/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "      <td>126</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "      <td>139</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>733</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>454</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "      <td>799</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ğŸ‘€ kuch b...</td>\n",
       "      <td>102</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "      <td>745</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16122 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text  \\\n",
       "0           ham  make sure alex knows his birthday is over in f...   \n",
       "1           ham  a resume for john lavorato thanks vince i will...   \n",
       "2          spam  plzz visit my website moviesgodml to get all m...   \n",
       "3          spam  urgent your mobile number has been awarded wit...   \n",
       "4           ham  overview of hr associates analyst project per ...   \n",
       "...         ...                                                ...   \n",
       "16273      spam  if you are interested in binary options tradin...   \n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...   \n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...   \n",
       "16276       ham  insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ğŸ‘€ kuch b...   \n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...   \n",
       "\n",
       "       num_characters  num_words  num_sentence  target  \n",
       "0                  86         16             1       0  \n",
       "1                 520         97             1       0  \n",
       "2                 126         22             1       1  \n",
       "3                 139         23             1       1  \n",
       "4                 733        127             1       0  \n",
       "...               ...        ...           ...     ...  \n",
       "16273             114         18             1       1  \n",
       "16274             454         74             1       1  \n",
       "16275             799        147             1       0  \n",
       "16276             102         21             1       0  \n",
       "16277             745        140             1       0  \n",
       "\n",
       "[16122 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ñ†ĞµĞ»Ğ¾Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ğ¾Ğµ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ»Ğ°ÑÑĞ¾Ğ² (0-ham, 1-spam)\n",
    "encoder = LabelEncoder()\n",
    "train_df['target'] = encoder.fit_transform(train_df['text_type'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad807e9c-f758-4939-8930-54215c38c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° Ğ´Ğ»Ñ ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³Ğ°\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Ğ¤-Ñ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ‚ĞµĞºÑÑ‚Ğ°\n",
    "def transform_text(text):\n",
    "    # Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´ Ğ² Ğ½Ğ¸Ğ¶Ğ½Ğ¸Ğ¹ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ»Ğ¸ÑˆĞ½Ğ¸Ğµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "            \n",
    "    # ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑÑ‚Ğ¾Ğ¿-ÑĞ»Ğ¾Ğ²Ğ° Ğ¸ Ğ¿ÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ñ\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "        \n",
    "    # ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0da89875-372e-4842-b64c-d480dfb787db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>make sure alex know birthday fifteen minut far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>resum john lavorato thank vinc get move right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>733</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>overview hr associ analyst project per david r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>url url date not supplied government employees...</td>\n",
       "      <td>156</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>url url date suppli govern employe routin scre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>looks like your ham corpus by and large has to...</td>\n",
       "      <td>419</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>look like ham corpu larg jeremi url header spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>spam</td>\n",
       "      <td>got bored right? ğŸ˜ then certainly you must che...</td>\n",
       "      <td>271</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>got bore right certainli must check netflix ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>spam</td>\n",
       "      <td>hey you know about this app i have earned 100 ...</td>\n",
       "      <td>244</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hey know app earn 100 rupe app also want earn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>spam</td>\n",
       "      <td>pvt finance arranged on cheque basics 4 busine...</td>\n",
       "      <td>132</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pvt financ arrang chequ basic 4 busi peopl tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>spam</td>\n",
       "      <td>ğ‘®ğ’ğ’ğ’… ğ’Šğ’ğ’—ğ’†ğ’”ğ’•ğ’ğ’†ğ’ğ’• ğ’‰ğ’‚ğ’” ğ’ƒğ’†ğ’†ğ’ ğ’ğ’š ğ’ğ’‚ğ’Šğ’ ğ’”ğ’ğ’–ğ’“ğ’„ğ’† ğ’ğ’‡ ğ’Šğ’ğ’„...</td>\n",
       "      <td>326</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ğ‘®ğ’ğ’ğ’… ğ’Šğ’ğ’—ğ’†ğ’”ğ’•ğ’ğ’†ğ’ğ’• ğ’‰ğ’‚ğ’” ğ’ƒğ’†ğ’†ğ’ ğ’ğ’š ğ’ğ’‚ğ’Šğ’ ğ’”ğ’ğ’–ğ’“ğ’„ğ’† ğ’ğ’‡ ğ’Šğ’ğ’„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>spam</td>\n",
       "      <td>i am so happy i made the right decision invest...</td>\n",
       "      <td>485</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>happi made right decis invest 1000 trade make ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_type                                               text  \\\n",
       "0          ham  make sure alex knows his birthday is over in f...   \n",
       "1          ham  a resume for john lavorato thanks vince i will...   \n",
       "2          ham  overview of hr associates analyst project per ...   \n",
       "3          ham  url url date not supplied government employees...   \n",
       "4          ham  looks like your ham corpus by and large has to...   \n",
       "...        ...                                                ...   \n",
       "3995      spam  got bored right? ğŸ˜ then certainly you must che...   \n",
       "3996      spam  hey you know about this app i have earned 100 ...   \n",
       "3997      spam  pvt finance arranged on cheque basics 4 busine...   \n",
       "3998      spam  ğ‘®ğ’ğ’ğ’… ğ’Šğ’ğ’—ğ’†ğ’”ğ’•ğ’ğ’†ğ’ğ’• ğ’‰ğ’‚ğ’” ğ’ƒğ’†ğ’†ğ’ ğ’ğ’š ğ’ğ’‚ğ’Šğ’ ğ’”ğ’ğ’–ğ’“ğ’„ğ’† ğ’ğ’‡ ğ’Šğ’ğ’„...   \n",
       "3999      spam  i am so happy i made the right decision invest...   \n",
       "\n",
       "      num_characters  num_words  num_sentence  target  \\\n",
       "0                 86         16             1       0   \n",
       "1                520         97             1       0   \n",
       "2                733        127             1       0   \n",
       "3                156         26             1       0   \n",
       "4                419         85             1       0   \n",
       "...              ...        ...           ...     ...   \n",
       "3995             271         50             2       1   \n",
       "3996             244         47             1       1   \n",
       "3997             132         20             1       1   \n",
       "3998             326         61             1       1   \n",
       "3999             485         93             1       1   \n",
       "\n",
       "                                       transformed_text  \n",
       "0     make sure alex know birthday fifteen minut far...  \n",
       "1     resum john lavorato thank vinc get move right ...  \n",
       "2     overview hr associ analyst project per david r...  \n",
       "3     url url date suppli govern employe routin scre...  \n",
       "4     look like ham corpu larg jeremi url header spa...  \n",
       "...                                                 ...  \n",
       "3995  got bore right certainli must check netflix ne...  \n",
       "3996  hey know app earn 100 rupe app also want earn ...  \n",
       "3997  pvt financ arrang chequ basic 4 busi peopl tra...  \n",
       "3998  ğ‘®ğ’ğ’ğ’… ğ’Šğ’ğ’—ğ’†ğ’”ğ’•ğ’ğ’†ğ’ğ’• ğ’‰ğ’‚ğ’” ğ’ƒğ’†ğ’†ğ’ ğ’ğ’š ğ’ğ’‚ğ’Šğ’ ğ’”ğ’ğ’–ğ’“ğ’„ğ’† ğ’ğ’‡ ğ’Šğ’ğ’„...  \n",
       "3999  happi made right decis invest 1000 trade make ...  \n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸\n",
    "train_df['transformed_text'] = train_df['text'].apply(transform_text)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69a39e45-a627-48f3-9e65-5be40b83d50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>733</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>url url date not supplied government employees...</td>\n",
       "      <td>156</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>looks like your ham corpus by and large has to...</td>\n",
       "      <td>419</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>spam</td>\n",
       "      <td>got bored right? ğŸ˜ then certainly you must che...</td>\n",
       "      <td>271</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>spam</td>\n",
       "      <td>hey you know about this app i have earned 100 ...</td>\n",
       "      <td>244</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>spam</td>\n",
       "      <td>pvt finance arranged on cheque basics 4 busine...</td>\n",
       "      <td>132</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>spam</td>\n",
       "      <td>ğ‘®ğ’ğ’ğ’… ğ’Šğ’ğ’—ğ’†ğ’”ğ’•ğ’ğ’†ğ’ğ’• ğ’‰ğ’‚ğ’” ğ’ƒğ’†ğ’†ğ’ ğ’ğ’š ğ’ğ’‚ğ’Šğ’ ğ’”ğ’ğ’–ğ’“ğ’„ğ’† ğ’ğ’‡ ğ’Šğ’ğ’„...</td>\n",
       "      <td>326</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>spam</td>\n",
       "      <td>i am so happy i made the right decision invest...</td>\n",
       "      <td>485</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_type                                               text  \\\n",
       "0          ham  make sure alex knows his birthday is over in f...   \n",
       "1          ham  a resume for john lavorato thanks vince i will...   \n",
       "2          ham  overview of hr associates analyst project per ...   \n",
       "3          ham  url url date not supplied government employees...   \n",
       "4          ham  looks like your ham corpus by and large has to...   \n",
       "...        ...                                                ...   \n",
       "3995      spam  got bored right? ğŸ˜ then certainly you must che...   \n",
       "3996      spam  hey you know about this app i have earned 100 ...   \n",
       "3997      spam  pvt finance arranged on cheque basics 4 busine...   \n",
       "3998      spam  ğ‘®ğ’ğ’ğ’… ğ’Šğ’ğ’—ğ’†ğ’”ğ’•ğ’ğ’†ğ’ğ’• ğ’‰ğ’‚ğ’” ğ’ƒğ’†ğ’†ğ’ ğ’ğ’š ğ’ğ’‚ğ’Šğ’ ğ’”ğ’ğ’–ğ’“ğ’„ğ’† ğ’ğ’‡ ğ’Šğ’ğ’„...   \n",
       "3999      spam  i am so happy i made the right decision invest...   \n",
       "\n",
       "      num_characters  num_words  num_sentence  target  \n",
       "0                 86         16             1       0  \n",
       "1                520         97             1       0  \n",
       "2                733        127             1       0  \n",
       "3                156         26             1       0  \n",
       "4                419         85             1       0  \n",
       "...              ...        ...           ...     ...  \n",
       "3995             271         50             2       1  \n",
       "3996             244         47             1       1  \n",
       "3997             132         20             1       1  \n",
       "3998             326         61             1       1  \n",
       "3999             485         93             1       1  \n",
       "\n",
       "[4000 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ²Ğ¾Ğ·ÑŒĞ¼ĞµĞ¼ ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºÑƒ Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ğ¼ undersampling Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ\n",
    "df_class_0 = train_df[train_df['target'] == 0][:2000]\n",
    "df_class_1 = train_df[train_df['target'] == 1][:2000]\n",
    "\n",
    "train_df_2 = pd.concat([df_class_0, df_class_1], ignore_index=True)\n",
    "train_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9894b06a-c970-4c36-8a13-6e29968c703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°\n",
    "tfid = TfidfVectorizer(max_features = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94cc2ee3-e589-4e4f-ba7d-1d8f9abc67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\n",
    "X = tfid.fit_transform(train_df['transformed_text']).toarray()\n",
    "y = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "669ff5c8-6674-4c32-98ae-a796ffe9a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ½Ğ° train-test\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 44)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e1a5dd-4663-4b36-a13e-654df1a7dde6",
   "metadata": {},
   "source": [
    "### 3. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ddf1cc1-a60d-4ea0-8c6f-673983b353a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6644d21d-6e8c-49e2-8ee6-537f95658769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹-ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¸Ğ· Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ sklearn\n",
    "\n",
    "svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "lrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\n",
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d8a148d6-05f1-4019-807b-cebc69a3b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ñ„-Ñ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ\n",
    "def train_classifier(clfs, X_train, y_train, X_test, y_test):\n",
    "    clfs.fit(X_train,y_train)\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    return accuracy, precision, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a2d8394c-3002-491e-b236-d58758995577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.91\n",
      "Precision:  0.9205128205128205\n",
      "Roc_auc:  0.9099999999999999\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.63125\n",
      "Precision:  0.9411764705882353\n",
      "Roc_auc:  0.63125\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.88625\n",
      "Precision:  0.8652482269503546\n",
      "Roc_auc:  0.88625\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.65875\n",
      "Precision:  0.5960665658093798\n",
      "Roc_auc:  0.65875\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.8675\n",
      "Precision:  0.8888888888888888\n",
      "Roc_auc:  0.8674999999999999\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.92125\n",
      "Precision:  0.9309462915601023\n",
      "Roc_auc:  0.9212500000000001\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.8175\n",
      "Precision:  0.8691860465116279\n",
      "Roc_auc:  0.8175\n",
      "\n",
      "For:  Bgc\n",
      "Accuracy:  0.87375\n",
      "Precision:  0.8673218673218673\n",
      "Roc_auc:  0.87375\n",
      "\n",
      "For:  ETC\n",
      "Accuracy:  0.92125\n",
      "Precision:  0.924433249370277\n",
      "Roc_auc:  0.92125\n",
      "\n",
      "For:  GBDT\n",
      "Accuracy:  0.81125\n",
      "Precision:  0.8738738738738738\n",
      "Roc_auc:  0.81125\n",
      "\n",
      "For:  xgb\n",
      "Accuracy:  0.87625\n",
      "Precision:  0.903485254691689\n",
      "Roc_auc:  0.8762500000000001\n"
     ]
    }
   ],
   "source": [
    "# Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ½Ğ¾Ğ¼ ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "roc_auc_scores = []\n",
    "for name, clf in clfs.items():\n",
    "    current_accuracy, current_precision, current_roc_auc = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    print(\"Roc_auc: \", current_roc_auc)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "    roc_auc_scores.append(current_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d893688d-3f24-43c3-b196-e7d82951766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.932093023255814\n",
      "Precision:  0.9190421892816419\n",
      "Roc_auc:  0.9067999855991183\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.7996899224806202\n",
      "Precision:  0.9529411764705882\n",
      "Roc_auc:  0.6662886435200186\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.9221705426356589\n",
      "Precision:  0.8866886688668867\n",
      "Roc_auc:  0.8997546311297215\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.782015503875969\n",
      "Precision:  0.8658892128279884\n",
      "Roc_auc:  0.6455326803087328\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.9249612403100775\n",
      "Precision:  0.9208037825059102\n",
      "Roc_auc:  0.8935297115115663\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.937984496124031\n",
      "Precision:  0.928409090909091\n",
      "Roc_auc:  0.914326523377893\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.8874418604651163\n",
      "Precision:  0.8793324775353016\n",
      "Roc_auc:  0.8383189462985579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ (Ğ½Ğµ ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "roc_auc_scores = []\n",
    "for name, clf in clfs.items():\n",
    "    current_accuracy, current_precision, current_roc_auc = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    print(\"Roc_auc: \", current_roc_auc)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "    roc_auc_scores.append(current_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a69ae758-eca6-4478-8349-365ea5b348a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4806"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ¿Ğ¾ĞºĞ° Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¾ Ñ‚Ğ¾Ğ¼, Ñ‡Ñ‚Ğ¾ Ğ½Ğ° ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ Ñ Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ¼ ĞºĞ¾Ğ»-Ğ²Ğ¾Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ² roc_auc Ğ²Ñ‹ÑˆĞµ (Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° Ñ‚Ğ¾ Ñ‡Ñ‚Ğ¾ accuracy Ğ¼ĞµĞ½ÑŒÑˆĞµ)  \n",
    "# ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºÑƒ, Ğ½Ğ¾ Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ ĞµĞµ ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹\n",
    "\n",
    "# Ğ¾Ğ±Ñ‰ĞµĞµ ĞºĞ¾Ğ»-Ğ²Ğ¾ ÑÑ‚Ñ€Ğ¾Ğº ĞºĞ»Ğ°ÑÑĞ° 1\n",
    "max_len = len(train_df[train_df['target'] == 1])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "caf6220f-7ef6-4df1-8e22-857ab92490ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>make sure alex know birthday fifteen minut far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>resum john lavorato thank vinc get move right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>733</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>overview hr associ analyst project per david r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>url url date not supplied government employees...</td>\n",
       "      <td>156</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>url url date suppli govern employe routin scre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>looks like your ham corpus by and large has to...</td>\n",
       "      <td>419</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>look like ham corpu larg jeremi url header spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9607</th>\n",
       "      <td>spam</td>\n",
       "      <td>your e mail to anvasetc 1111 groups msn com ca...</td>\n",
       "      <td>429</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>e mail anvasetc 1111 group msn com deliv sent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9608</th>\n",
       "      <td>spam</td>\n",
       "      <td>rs 250 for dental services worth rs 2150 denta...</td>\n",
       "      <td>130</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rs 250 dental servic worth rs 2150 dental spa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9609</th>\n",
       "      <td>spam</td>\n",
       "      <td>dost i am playing cricket knifeup pool etc and...</td>\n",
       "      <td>196</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dost play cricket knifeup pool etc win cash da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9610</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>interest binari option trade may continu infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9611</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>454</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dirti pictureblyk aircel thank valu member her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9612 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_type                                               text  \\\n",
       "0          ham  make sure alex knows his birthday is over in f...   \n",
       "1          ham  a resume for john lavorato thanks vince i will...   \n",
       "2          ham  overview of hr associates analyst project per ...   \n",
       "3          ham  url url date not supplied government employees...   \n",
       "4          ham  looks like your ham corpus by and large has to...   \n",
       "...        ...                                                ...   \n",
       "9607      spam  your e mail to anvasetc 1111 groups msn com ca...   \n",
       "9608      spam  rs 250 for dental services worth rs 2150 denta...   \n",
       "9609      spam  dost i am playing cricket knifeup pool etc and...   \n",
       "9610      spam  if you are interested in binary options tradin...   \n",
       "9611      spam  dirty pictureblyk on aircel thanks you for bei...   \n",
       "\n",
       "      num_characters  num_words  num_sentence  target  \\\n",
       "0                 86         16             1       0   \n",
       "1                520         97             1       0   \n",
       "2                733        127             1       0   \n",
       "3                156         26             1       0   \n",
       "4                419         85             1       0   \n",
       "...              ...        ...           ...     ...   \n",
       "9607             429         87             1       1   \n",
       "9608             130         24             1       1   \n",
       "9609             196         38             2       1   \n",
       "9610             114         18             1       1   \n",
       "9611             454         74             1       1   \n",
       "\n",
       "                                       transformed_text  \n",
       "0     make sure alex know birthday fifteen minut far...  \n",
       "1     resum john lavorato thank vinc get move right ...  \n",
       "2     overview hr associ analyst project per david r...  \n",
       "3     url url date suppli govern employe routin scre...  \n",
       "4     look like ham corpu larg jeremi url header spa...  \n",
       "...                                                 ...  \n",
       "9607  e mail anvasetc 1111 group msn com deliv sent ...  \n",
       "9608  rs 250 dental servic worth rs 2150 dental spa ...  \n",
       "9609  dost play cricket knifeup pool etc win cash da...  \n",
       "9610  interest binari option trade may continu infor...  \n",
       "9611  dirti pictureblyk aircel thank valu member her...  \n",
       "\n",
       "[9612 rows x 7 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ²Ğ¾Ğ·ÑŒĞ¼ĞµĞ¼ ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºÑƒ Ñ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°\n",
    "df_class_0 = train_df[train_df['target'] == 0][:max_len]\n",
    "df_class_1 = train_df[train_df['target'] == 1][:max_len]\n",
    "\n",
    "train_df_2 = pd.concat([df_class_0, df_class_1], ignore_index=True)\n",
    "train_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "586be22e-4391-40fd-ae4f-b854b6d397a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ñ‚Ñ€ĞµĞ¹Ğ½ Ğ¸ Ñ‚ĞµÑÑ‚\n",
    "X = tfid.fit_transform(train_df_2['transformed_text']).toarray()\n",
    "y = train_df_2['target'].values\n",
    "\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4f474c4a-a696-4c80-be84-a2633a30ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.9121164846593863\n",
      "Precision:  0.9290393013100436\n",
      "Roc_auc:  0.9119753580546061\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.642225689027561\n",
      "Precision:  0.9651567944250871\n",
      "Roc_auc:  0.6398608887542728\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.8881955278211129\n",
      "Precision:  0.8592233009708737\n",
      "Roc_auc:  0.888454091125438\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.6640665626625065\n",
      "Precision:  0.5979708306911858\n",
      "Roc_auc:  0.6662379386439359\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.8975559022360895\n",
      "Precision:  0.9155701754385965\n",
      "Roc_auc:  0.8974000475963826\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.9235569422776911\n",
      "Precision:  0.9400871459694989\n",
      "Roc_auc:  0.9234233698238934\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.84399375975039\n",
      "Precision:  0.8857479387514723\n",
      "Roc_auc:  0.8436139717017871\n",
      "\n",
      "For:  Bgc\n",
      "Accuracy:  0.8965158606344253\n",
      "Precision:  0.8913043478260869\n",
      "Roc_auc:  0.8965498031240535\n",
      "\n",
      "For:  ETC\n",
      "Accuracy:  0.9209568382735309\n",
      "Precision:  0.9195402298850575\n",
      "Roc_auc:  0.9209602570204665\n",
      "\n",
      "For:  GBDT\n",
      "Accuracy:  0.8289131565262611\n",
      "Precision:  0.9151193633952255\n",
      "Roc_auc:  0.8281986932629484\n",
      "\n",
      "For:  xgb\n",
      "Accuracy:  0.890795631825273\n",
      "Precision:  0.9296424452133795\n",
      "Roc_auc:  0.8904812643330016\n"
     ]
    }
   ],
   "source": [
    "# Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "roc_auc_scores = []\n",
    "for name, clf in clfs.items():\n",
    "    current_accuracy, current_precision, current_roc_auc = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    print(\"Roc_auc: \", current_roc_auc)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "    roc_auc_scores.append(current_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaccce5-c68d-4987-9e0b-e26ee3372d16",
   "metadata": {},
   "source": [
    "### 4. Ğ”Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41578fec-78f9-4498-966e-35835c7a5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ - ETC, RF, SVC\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸\n",
    "clfs = {\n",
    "    'ETC': ExtraTreesClassifier(random_state=42),\n",
    "    'RF': RandomForestClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ \n",
    "param_grid = {\n",
    "    'ETC': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 4, 6]\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²\n",
    "best_models = {}\n",
    "\n",
    "# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ ÑĞºĞ¾Ñ€ĞµÑ€Ğ°\n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "# Ğ¦Ğ¸ĞºĞ» Ğ¿Ğ¾ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼\n",
    "for name, clf in clfs.items():\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid[name], scoring=scorers, refit='roc_auc', n_jobs=-1, cv=3, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    \n",
    "    # Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²\n",
    "    print(f\"Ğ›ÑƒÑ‡ÑˆĞ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ {name}: {grid_search.best_params_}\")\n",
    "    y_pred = best_models[name].predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f91bf-e37f-4f5b-9267-b8195c4da11e",
   "metadata": {},
   "source": [
    "Ğ›ÑƒÑ‡ÑˆĞ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ ETC: {'max_features': 'log2', 'min_samples_split': 6, 'n_estimators': 200}  #2\n",
    "Accuracy: 0.9318772750910036\n",
    "Precision: 0.9291666666666667\n",
    "ROC AUC: 0.931891739864134\n",
    "\n",
    "Ğ›ÑƒÑ‡ÑˆĞ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ RF: {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 100}\n",
    "Accuracy: 0.9162766510660426\n",
    "Precision: 0.9241452991452992\n",
    "ROC AUC: 0.9162060274328242\n",
    "\n",
    "Ğ›ÑƒÑ‡ÑˆĞ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ SVC: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "Accuracy: 0.9334373374934998\n",
    "Precision: 0.9431939978563773\n",
    "ROC AUC: 0.9333569512353426"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665aa4db-5dc0-43fb-aa90-b428a581e03f",
   "metadata": {},
   "source": [
    "### 5. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cacbbf13-a1bb-4683-b5de-af4c9adc9310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9360374414976599\n",
      "Precision: 0.9378947368421052\n",
      "ROC AUC: 0.9360169399852883\n"
     ]
    }
   ],
   "source": [
    "# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
    "classifiers = [\n",
    "    ('rf', ExtraTreesClassifier(n_estimators=200, max_features='log2', min_samples_split=6, random_state=42)),\n",
    "    ('etc', RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_depth=None, random_state=42)),\n",
    "    ('svc', SVC(C=10, gamma='scale', kernel='rbf', random_state=42))\n",
    "]\n",
    "\n",
    "# ĞœĞµÑ‚Ğ°-ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€\n",
    "meta_classifier = LogisticRegression()\n",
    "\n",
    "# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑÑ‚ĞµĞºĞ¸Ğ½Ğ³-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
    "stacking_model = StackingClassifier(estimators=classifiers, final_estimator=meta_classifier, cv=5)\n",
    "\n",
    "# ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚ĞµĞºĞ¸Ğ½Ğ³-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# ĞÑ†ĞµĞ½ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dbd2af-c6af-4f2f-89af-144a8efb9118",
   "metadata": {},
   "source": [
    "### 6. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ transformer https://huggingface.co/mshenoda/roberta-spam?text=delivery+status+notification+failure+the+following+message+to+was+undeliverable+the+reason+for+the+problem+5+1+0+unknown+address+error+550+5+1+1+unknown+or+illegal+alias+gkoppmal+elp+rr+com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f0d22933-858a-401d-9627-f48cf198065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mshenoda/roberta-spam\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mshenoda/roberta-spam\")\n",
    "\n",
    "# ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts.iloc[idx]\n",
    "\n",
    "# CĞ¿Ğ¸ÑĞ¾Ğº Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²\n",
    "texts = train_df['text'][:1000]\n",
    "\n",
    "# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°\n",
    "dataset = TextDataset(texts)\n",
    "\n",
    "# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ DataLoader Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ±Ğ°Ñ‚Ñ‡Ğ°Ğ¼Ğ¸\n",
    "loader = DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ±Ğ°Ñ‚Ñ‡ĞµĞ¹\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    for batch in dataloader:\n",
    "        texts = batch\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            probabilities.extend(probs.tolist())\n",
    "            predictions.extend(preds.tolist())\n",
    "    return probabilities, predictions\n",
    "\n",
    "# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹\n",
    "probabilities, predictions = predict(model, loader)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6e06530c-9825-4beb-a083-9d6aea444a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.998\n",
      "Precision: 0.9965986394557823\n",
      "ROC AUC: 0.9975911044304407\n"
     ]
    }
   ],
   "source": [
    "# Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°\n",
    "y_test = train_df['target'][:1000]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "print(f\"Precision: {precision_score(y_test, predictions)}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378ff41-6afb-4555-9dbe-b2bc127023b0",
   "metadata": {},
   "source": [
    "### 7. ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9ba88927-ade0-4341-88ad-f28eb6dd87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j jim whitehead ejw cse ucsc edu writes j you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original message from bitbitch magnesium net p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java for managers vince durasoft who just taug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a youtuber name saiman says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>underpriced issue with high return on equity t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>husband to wifetum meri zindagi hoorwifeor kya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>baylor enron case study cindy yes i shall co a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>boring as compared to tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>hellogorgeous hows u my fone was on charge lst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>energy conference mark we are really swamped a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     j jim whitehead ejw cse ucsc edu writes j you ...\n",
       "1     original message from bitbitch magnesium net p...\n",
       "2     java for managers vince durasoft who just taug...\n",
       "3                  there is a youtuber name saiman says\n",
       "4     underpriced issue with high return on equity t...\n",
       "...                                                 ...\n",
       "4065  husband to wifetum meri zindagi hoorwifeor kya...\n",
       "4066  baylor enron case study cindy yes i shall co a...\n",
       "4067                           boring as compared to tp\n",
       "4068  hellogorgeous hows u my fone was on charge lst...\n",
       "4069  energy conference mark we are really swamped a...\n",
       "\n",
       "[4070 rows x 1 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_spam.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3c598608-2e88-4338-b18f-98f644b333eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿ÑƒÑÑ‚Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9d450ea1-85bb-463f-acc4-e2f362d9996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "texts = test_df['text']\n",
    "\n",
    "dataset = TextDataset(texts)\n",
    "loader = DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ±Ğ°Ñ‚Ñ‡ĞµĞ¹\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        print(f'Batch {idx}')\n",
    "        texts = batch\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            probabilities.extend(probs.tolist())\n",
    "            predictions.extend(preds.tolist())\n",
    "    return probabilities, predictions\n",
    "\n",
    "# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹\n",
    "probabilities, predictions = predict(model, loader)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "90ea957e-10d1-42b7-9b56-b6e68e191917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ñ„-Ñ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ° Ñ†ĞµĞ»Ğ¾Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğº ĞºĞ»Ğ°ÑÑĞ° Ğ² ham/spam\n",
    "def decode_prediction(class_prediction):\n",
    "    if class_prediction == 0:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'spam'\n",
    "\n",
    "test_df['class_prediction'] = predictions\n",
    "test_df['score'] = test_df['class_prediction'].apply(decode_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fafbbe8b-7fb1-4774-b290-3aec5d3b173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
    "test_df[['score', 'text']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
