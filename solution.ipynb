{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba110bf0-0874-4704-807d-38b67efdd511",
   "metadata": {},
   "source": [
    "- –≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –∑–∞–¥–∞—á–∏ –°–ü–ê–ú-–¥–µ—Ç–µ–∫—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è).\n",
    "- –í –∫–∞—á–µ—Å—Ç–≤–µ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è roc_auc, –æ–¥–Ω–∞–∫–æ —è —Ç–∞–∫–∂–µ —Ä–µ—à–∏–ª–∞ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ precision, —Ç.–∫. –≤ –¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ –≤–∞–∂–Ω–∞ –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è false positives –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Å–ª—É—á–∞–π–Ω–æ –Ω–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –≤–∞–∂–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ —Å–ø–∞–º\n",
    "\n",
    "  \n",
    "*–ë—ã–ª–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã*:\n",
    "- –û–±—É—á–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ sklearn –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ—Ç–ø—Ä–∞–≤–Ω–æ–π —Ç–æ—á–∫–∏. –ù–∞–∏–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∫–∞–∑–∞–ª–∏ SVM, RandomForest, ExtraTreesClassifier. –û–¥–Ω–∞–∫–æ roc_auc –Ω–µ –ø—Ä–µ–≤—ã—Å–∏–ª 0.93\n",
    "- –î–ª—è –ª—É—á—à–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω GridSearch –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–¥–Ω–∞–∫–æ roc_auc —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è\n",
    "- –°—Ç–µ–∫–∏–Ω–≥ –∏–∑ –ª—É—á—à–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –≤—ã—à–µ, roc_auc —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è\n",
    "- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ roberta –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ hugginface. –ó–¥–µ—Å—å –¥–∞–∂–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–µ –ø–æ–Ω–∞–¥–æ–±–∏–ª–æ—Å—å, —Ç.–∫. –º–æ–¥–µ–ª—å —É–∂–µ –±—ã–ª–∞ –¥–æ–æ–±—É—á–µ–Ω–∞ –Ω–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –∏ –ø–æ–∫–∞–∑–∞–ª–∞ –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ roc_auc=0.99. –≠—Ç–∞ –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68649cd8-1528-4fe3-b222-844a8b540689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∑–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c337a-0066-4a68-aa2c-c2987360dbd2",
   "metadata": {},
   "source": [
    "### 1. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a417415d-db09-408d-8763-bb23fa062371",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥—ã**\n",
    "1. –í —Ç—Ä–µ–π–Ω –¥–∞—Ç–∞—Å–µ—Ç–µ 16278 —Å—Ç—Ä–æ–∫ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ\n",
    "2. –ï—Å—Ç—å 2 –∫–ª–∞—Å—Å–∞ - spam –∏ ham (–Ω—É–∂–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ —á–∏—Å–ª–∞–º–∏ 0 –∏–ª–∏ 1)\n",
    "3. –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç\n",
    "4. –ï—Å—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ (–ø—Ä–µ–æ–±–ª–∞–¥–∞–µ—Ç –∫–ª–∞—Å—Å 0). –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ª—É—á—à–µ –±—Ä–∞—Ç—å —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "5. –ï—Å—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68a1f1f-f721-4ac2-82d2-139f251bb663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 ‡§ó‡§Ç‡§¶ bhara pada hai üëÄ kuch b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text\n",
       "0           ham  make sure alex knows his birthday is over in f...\n",
       "1           ham  a resume for john lavorato thanks vince i will...\n",
       "2          spam  plzz visit my website moviesgodml to get all m...\n",
       "3          spam  urgent your mobile number has been awarded wit...\n",
       "4           ham  overview of hr associates analyst project per ...\n",
       "...         ...                                                ...\n",
       "16273      spam  if you are interested in binary options tradin...\n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...\n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...\n",
       "16276       ham  insta reels par 80 ‡§ó‡§Ç‡§¶ bhara pada hai üëÄ kuch b...\n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...\n",
       "\n",
       "[16278 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "train_df = pd.read_csv('train_spam.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6ea38b-4588-46dc-a091-9d02e23c31ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16278 entries, 0 to 16277\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text_type  16278 non-null  object\n",
      " 1   text       16278 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 254.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea63af2-ecf1-4742-a8b6-c2e03e86ab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_type    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da015d7-3881-46a9-a400-e3f75b56695e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ—Ä\n",
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe98d6c3-7deb-4112-96c2-655ab93dde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "train_df = train_df.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bed64ec-e16f-4274-8aee-9655e4592acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of 0 : 70.4370812073523\n",
      "percentage of 1 : 29.56291879264769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/9dxsk7gs7fxg8nmzktwnpj0w0000gn/T/ipykernel_9321/1985025021.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  percentage_0 = (values[0] /total) * 100\n",
      "/var/folders/1g/9dxsk7gs7fxg8nmzktwnpj0w0000gn/T/ipykernel_9321/1985025021.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  percentage_1 = (values[1]/ total) *100\n"
     ]
    }
   ],
   "source": [
    "# —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤\n",
    "values = train_df['text_type'].value_counts()\n",
    "total = values.sum()\n",
    "\n",
    "percentage_0 = (values[0] /total) * 100\n",
    "percentage_1 = (values[1]/ total) *100\n",
    "\n",
    "print('percentage of 0 :' ,percentage_0)\n",
    "print('percentage of 1 :' ,percentage_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "87672055-6d2b-4144-a118-56508f053526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª-–≤–µ —Å–∏–º–≤–æ–ª–æ–≤, —Å–ª–æ–≤ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "train_df['num_characters'] = train_df['text'].apply(len)\n",
    "train_df['num_words'] = train_df['text'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "train_df['num_sentence'] = train_df['text'].apply(lambda x: len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720333ad-80b7-4624-bac1-8fcef7076821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16267.000000</td>\n",
       "      <td>16267.000000</td>\n",
       "      <td>16267.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>310.468986</td>\n",
       "      <td>57.141944</td>\n",
       "      <td>1.062212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>287.887904</td>\n",
       "      <td>52.134400</td>\n",
       "      <td>0.376116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>157.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>639.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_characters     num_words  num_sentence\n",
       "count    16267.000000  16267.000000  16267.000000\n",
       "mean       310.468986     57.141944      1.062212\n",
       "std        287.887904     52.134400      0.376116\n",
       "min          1.000000      1.000000      1.000000\n",
       "25%         60.000000     12.000000      1.000000\n",
       "50%        157.000000     31.000000      1.000000\n",
       "75%        639.000000    114.000000      1.000000\n",
       "max        800.000000    207.000000     12.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['num_characters', 'num_words', 'num_sentence']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f9efa4a-337f-480c-b3c9-6af3371cf535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text  num_characters  num_words  num_sentence\n",
       "text_type                                               \n",
       "ham         142             142        142           142\n",
       "spam          3               3          3             3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ø–æ –æ—Ç—á–µ—Ç—É –≤–∏–¥–Ω–æ, —á—Ç–æ –µ—Å—Ç—å —Å—Ç—Ä–æ–∫–∏, –¥–ª–∏–Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö = 1 —Å–ª–æ–≤–æ. –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –æ–Ω–∏ –Ω–µ –Ω–µ—Å—É—Ç —Ü–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –ø–æ—ç—Ç–æ–º—É –∏—Ö –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å\n",
    "train_df[train_df['num_words'] < 2].groupby('text_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b010570d-8810-4476-b995-251102b11d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ham</td>\n",
       "      <td>urgent</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>ham</td>\n",
       "      <td>fast</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>ham</td>\n",
       "      <td>freemasonry</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>ham</td>\n",
       "      <td>logs</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>ham</td>\n",
       "      <td>landed</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15738</th>\n",
       "      <td>ham</td>\n",
       "      <td>txt</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15780</th>\n",
       "      <td>ham</td>\n",
       "      <td>staffsciencenusedusgphyhcmkteachingpc1323</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15890</th>\n",
       "      <td>ham</td>\n",
       "      <td>derpherp</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16067</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16230</th>\n",
       "      <td>ham</td>\n",
       "      <td>sax</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                       text  num_characters  \\\n",
       "76          ham                                     urgent               6   \n",
       "149         ham                                       fast               4   \n",
       "170         ham                                freemasonry              11   \n",
       "233         ham                                       logs               4   \n",
       "331         ham                                     landed               6   \n",
       "...         ...                                        ...             ...   \n",
       "15738       ham                                        txt               3   \n",
       "15780       ham  staffsciencenusedusgphyhcmkteachingpc1323              41   \n",
       "15890       ham                                   derpherp               8   \n",
       "16067       ham                                         ok               2   \n",
       "16230       ham                                        sax               3   \n",
       "\n",
       "       num_words  num_sentence  \n",
       "76             1             1  \n",
       "149            1             1  \n",
       "170            1             1  \n",
       "233            1             1  \n",
       "331            1             1  \n",
       "...          ...           ...  \n",
       "15738          1             1  \n",
       "15780          1             1  \n",
       "15890          1             1  \n",
       "16067          1             1  \n",
       "16230          1             1  \n",
       "\n",
       "[145 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice_to_drop = train_df[train_df['num_words'] < 2].index\n",
    "train_df[train_df['num_words'] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e43dc-df61-45df-8291-b6fe08467e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å—Ç—Ä–æ–∫\n",
    "train_df = train_df.drop(indice_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d3de8-2dc2-4adf-b2fb-bb875684a0f6",
   "metadata": {},
   "source": [
    "### 2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a46b53b-ee1b-4055-b8f2-d0f4e7b3d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irinba/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/irinba/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "      <td>126</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "      <td>139</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>733</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>454</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "      <td>799</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 ‡§ó‡§Ç‡§¶ bhara pada hai üëÄ kuch b...</td>\n",
       "      <td>102</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "      <td>745</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16122 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text  \\\n",
       "0           ham  make sure alex knows his birthday is over in f...   \n",
       "1           ham  a resume for john lavorato thanks vince i will...   \n",
       "2          spam  plzz visit my website moviesgodml to get all m...   \n",
       "3          spam  urgent your mobile number has been awarded wit...   \n",
       "4           ham  overview of hr associates analyst project per ...   \n",
       "...         ...                                                ...   \n",
       "16273      spam  if you are interested in binary options tradin...   \n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...   \n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...   \n",
       "16276       ham  insta reels par 80 ‡§ó‡§Ç‡§¶ bhara pada hai üëÄ kuch b...   \n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...   \n",
       "\n",
       "       num_characters  num_words  num_sentence  target  \n",
       "0                  86         16             1       0  \n",
       "1                 520         97             1       0  \n",
       "2                 126         22             1       1  \n",
       "3                 139         23             1       1  \n",
       "4                 733        127             1       0  \n",
       "...               ...        ...           ...     ...  \n",
       "16273             114         18             1       1  \n",
       "16274             454         74             1       1  \n",
       "16275             799        147             1       0  \n",
       "16276             102         21             1       0  \n",
       "16277             745        140             1       0  \n",
       "\n",
       "[16122 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (0-ham, 1-spam)\n",
    "encoder = LabelEncoder()\n",
    "train_df['target'] = encoder.fit_transform(train_df['text_type'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad807e9c-f758-4939-8930-54215c38c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –¥–ª—è —Å—Ç–µ–º–º–∏–Ω–≥–∞\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# –§-—è –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "def transform_text(text):\n",
    "    # –ø–µ—Ä–µ–≤–æ–¥ –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä\n",
    "    text = text.lower()\n",
    "    \n",
    "    # —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "            \n",
    "    # —É–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "        \n",
    "    # —Å—Ç–µ–º–º–∏–Ω–≥\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0da89875-372e-4842-b64c-d480dfb787db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>make sure alex know birthday fifteen minut far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>resum john lavorato thank vinc get move right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>733</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>overview hr associ analyst project per david r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>url url date not supplied government employees...</td>\n",
       "      <td>156</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>url url date suppli govern employe routin scre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>looks like your ham corpus by and large has to...</td>\n",
       "      <td>419</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>look like ham corpu larg jeremi url header spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>spam</td>\n",
       "      <td>got bored right? üòê then certainly you must che...</td>\n",
       "      <td>271</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>got bore right certainli must check netflix ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>spam</td>\n",
       "      <td>hey you know about this app i have earned 100 ...</td>\n",
       "      <td>244</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hey know app earn 100 rupe app also want earn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>spam</td>\n",
       "      <td>pvt finance arranged on cheque basics 4 busine...</td>\n",
       "      <td>132</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pvt financ arrang chequ basic 4 busi peopl tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>spam</td>\n",
       "      <td>ùëÆùíêùíêùíÖ ùíäùíèùíóùíÜùíîùíïùíéùíÜùíèùíï ùíâùíÇùíî ùíÉùíÜùíÜùíè ùíéùíö ùíéùíÇùíäùíè ùíîùíêùíñùíìùíÑùíÜ ùíêùíá ùíäùíèùíÑ...</td>\n",
       "      <td>326</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ùëÆùíêùíêùíÖ ùíäùíèùíóùíÜùíîùíïùíéùíÜùíèùíï ùíâùíÇùíî ùíÉùíÜùíÜùíè ùíéùíö ùíéùíÇùíäùíè ùíîùíêùíñùíìùíÑùíÜ ùíêùíá ùíäùíèùíÑ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>spam</td>\n",
       "      <td>i am so happy i made the right decision invest...</td>\n",
       "      <td>485</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>happi made right decis invest 1000 trade make ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_type                                               text  \\\n",
       "0          ham  make sure alex knows his birthday is over in f...   \n",
       "1          ham  a resume for john lavorato thanks vince i will...   \n",
       "2          ham  overview of hr associates analyst project per ...   \n",
       "3          ham  url url date not supplied government employees...   \n",
       "4          ham  looks like your ham corpus by and large has to...   \n",
       "...        ...                                                ...   \n",
       "3995      spam  got bored right? üòê then certainly you must che...   \n",
       "3996      spam  hey you know about this app i have earned 100 ...   \n",
       "3997      spam  pvt finance arranged on cheque basics 4 busine...   \n",
       "3998      spam  ùëÆùíêùíêùíÖ ùíäùíèùíóùíÜùíîùíïùíéùíÜùíèùíï ùíâùíÇùíî ùíÉùíÜùíÜùíè ùíéùíö ùíéùíÇùíäùíè ùíîùíêùíñùíìùíÑùíÜ ùíêùíá ùíäùíèùíÑ...   \n",
       "3999      spam  i am so happy i made the right decision invest...   \n",
       "\n",
       "      num_characters  num_words  num_sentence  target  \\\n",
       "0                 86         16             1       0   \n",
       "1                520         97             1       0   \n",
       "2                733        127             1       0   \n",
       "3                156         26             1       0   \n",
       "4                419         85             1       0   \n",
       "...              ...        ...           ...     ...   \n",
       "3995             271         50             2       1   \n",
       "3996             244         47             1       1   \n",
       "3997             132         20             1       1   \n",
       "3998             326         61             1       1   \n",
       "3999             485         93             1       1   \n",
       "\n",
       "                                       transformed_text  \n",
       "0     make sure alex know birthday fifteen minut far...  \n",
       "1     resum john lavorato thank vinc get move right ...  \n",
       "2     overview hr associ analyst project per david r...  \n",
       "3     url url date suppli govern employe routin scre...  \n",
       "4     look like ham corpu larg jeremi url header spa...  \n",
       "...                                                 ...  \n",
       "3995  got bore right certainli must check netflix ne...  \n",
       "3996  hey know app earn 100 rupe app also want earn ...  \n",
       "3997  pvt financ arrang chequ basic 4 busi peopl tra...  \n",
       "3998  ùëÆùíêùíêùíÖ ùíäùíèùíóùíÜùíîùíïùíéùíÜùíèùíï ùíâùíÇùíî ùíÉùíÜùíÜùíè ùíéùíö ùíéùíÇùíäùíè ùíîùíêùíñùíìùíÑùíÜ ùíêùíá ùíäùíèùíÑ...  \n",
       "3999  happi made right decis invest 1000 trade make ...  \n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ø—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "train_df['transformed_text'] = train_df['text'].apply(transform_text)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69a39e45-a627-48f3-9e65-5be40b83d50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>733</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>url url date not supplied government employees...</td>\n",
       "      <td>156</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>looks like your ham corpus by and large has to...</td>\n",
       "      <td>419</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>spam</td>\n",
       "      <td>got bored right? üòê then certainly you must che...</td>\n",
       "      <td>271</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>spam</td>\n",
       "      <td>hey you know about this app i have earned 100 ...</td>\n",
       "      <td>244</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>spam</td>\n",
       "      <td>pvt finance arranged on cheque basics 4 busine...</td>\n",
       "      <td>132</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>spam</td>\n",
       "      <td>ùëÆùíêùíêùíÖ ùíäùíèùíóùíÜùíîùíïùíéùíÜùíèùíï ùíâùíÇùíî ùíÉùíÜùíÜùíè ùíéùíö ùíéùíÇùíäùíè ùíîùíêùíñùíìùíÑùíÜ ùíêùíá ùíäùíèùíÑ...</td>\n",
       "      <td>326</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>spam</td>\n",
       "      <td>i am so happy i made the right decision invest...</td>\n",
       "      <td>485</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_type                                               text  \\\n",
       "0          ham  make sure alex knows his birthday is over in f...   \n",
       "1          ham  a resume for john lavorato thanks vince i will...   \n",
       "2          ham  overview of hr associates analyst project per ...   \n",
       "3          ham  url url date not supplied government employees...   \n",
       "4          ham  looks like your ham corpus by and large has to...   \n",
       "...        ...                                                ...   \n",
       "3995      spam  got bored right? üòê then certainly you must che...   \n",
       "3996      spam  hey you know about this app i have earned 100 ...   \n",
       "3997      spam  pvt finance arranged on cheque basics 4 busine...   \n",
       "3998      spam  ùëÆùíêùíêùíÖ ùíäùíèùíóùíÜùíîùíïùíéùíÜùíèùíï ùíâùíÇùíî ùíÉùíÜùíÜùíè ùíéùíö ùíéùíÇùíäùíè ùíîùíêùíñùíìùíÑùíÜ ùíêùíá ùíäùíèùíÑ...   \n",
       "3999      spam  i am so happy i made the right decision invest...   \n",
       "\n",
       "      num_characters  num_words  num_sentence  target  \n",
       "0                 86         16             1       0  \n",
       "1                520         97             1       0  \n",
       "2                733        127             1       0  \n",
       "3                156         26             1       0  \n",
       "4                419         85             1       0  \n",
       "...              ...        ...           ...     ...  \n",
       "3995             271         50             2       1  \n",
       "3996             244         47             1       1  \n",
       "3997             132         20             1       1  \n",
       "3998             326         61             1       1  \n",
       "3999             485         93             1       1  \n",
       "\n",
       "[4000 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –≤–æ–∑—å–º–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É –∏ –≤—ã–ø–æ–ª–Ω–∏–º undersampling –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "df_class_0 = train_df[train_df['target'] == 0][:2000]\n",
    "df_class_1 = train_df[train_df['target'] == 1][:2000]\n",
    "\n",
    "train_df_2 = pd.concat([df_class_0, df_class_1], ignore_index=True)\n",
    "train_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9894b06a-c970-4c36-8a13-6e29968c703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞\n",
    "tfid = TfidfVectorizer(max_features = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94cc2ee3-e589-4e4f-ba7d-1d8f9abc67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "X = tfid.fit_transform(train_df['transformed_text']).toarray()\n",
    "y = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "669ff5c8-6674-4c32-98ae-a796ffe9a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∫–∏ –Ω–∞ train-test\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 44)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e1a5dd-4663-4b36-a13e-654df1a7dde6",
   "metadata": {},
   "source": [
    "### 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ddf1cc1-a60d-4ea0-8c6f-673983b353a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6644d21d-6e8c-49e2-8ee6-537f95658769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –º–æ–¥–µ–ª–µ–π-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ sklearn\n",
    "\n",
    "svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "lrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\n",
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d8a148d6-05f1-4019-807b-cebc69a3b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ñ-—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "def train_classifier(clfs, X_train, y_train, X_test, y_test):\n",
    "    clfs.fit(X_train,y_train)\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    return accuracy, precision, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a2d8394c-3002-491e-b236-d58758995577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.91\n",
      "Precision:  0.9205128205128205\n",
      "Roc_auc:  0.9099999999999999\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.63125\n",
      "Precision:  0.9411764705882353\n",
      "Roc_auc:  0.63125\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.88625\n",
      "Precision:  0.8652482269503546\n",
      "Roc_auc:  0.88625\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.65875\n",
      "Precision:  0.5960665658093798\n",
      "Roc_auc:  0.65875\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.8675\n",
      "Precision:  0.8888888888888888\n",
      "Roc_auc:  0.8674999999999999\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.92125\n",
      "Precision:  0.9309462915601023\n",
      "Roc_auc:  0.9212500000000001\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.8175\n",
      "Precision:  0.8691860465116279\n",
      "Roc_auc:  0.8175\n",
      "\n",
      "For:  Bgc\n",
      "Accuracy:  0.87375\n",
      "Precision:  0.8673218673218673\n",
      "Roc_auc:  0.87375\n",
      "\n",
      "For:  ETC\n",
      "Accuracy:  0.92125\n",
      "Precision:  0.924433249370277\n",
      "Roc_auc:  0.92125\n",
      "\n",
      "For:  GBDT\n",
      "Accuracy:  0.81125\n",
      "Precision:  0.8738738738738738\n",
      "Roc_auc:  0.81125\n",
      "\n",
      "For:  xgb\n",
      "Accuracy:  0.87625\n",
      "Precision:  0.903485254691689\n",
      "Roc_auc:  0.8762500000000001\n"
     ]
    }
   ],
   "source": [
    "# –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "roc_auc_scores = []\n",
    "for name, clf in clfs.items():\n",
    "    current_accuracy, current_precision, current_roc_auc = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    print(\"Roc_auc: \", current_roc_auc)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "    roc_auc_scores.append(current_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d893688d-3f24-43c3-b196-e7d82951766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.932093023255814\n",
      "Precision:  0.9190421892816419\n",
      "Roc_auc:  0.9067999855991183\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.7996899224806202\n",
      "Precision:  0.9529411764705882\n",
      "Roc_auc:  0.6662886435200186\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.9221705426356589\n",
      "Precision:  0.8866886688668867\n",
      "Roc_auc:  0.8997546311297215\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.782015503875969\n",
      "Precision:  0.8658892128279884\n",
      "Roc_auc:  0.6455326803087328\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.9249612403100775\n",
      "Precision:  0.9208037825059102\n",
      "Roc_auc:  0.8935297115115663\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.937984496124031\n",
      "Precision:  0.928409090909091\n",
      "Roc_auc:  0.914326523377893\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.8874418604651163\n",
      "Precision:  0.8793324775353016\n",
      "Roc_auc:  0.8383189462985579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (–Ω–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "roc_auc_scores = []\n",
    "for name, clf in clfs.items():\n",
    "    current_accuracy, current_precision, current_roc_auc = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    print(\"Roc_auc: \", current_roc_auc)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "    roc_auc_scores.append(current_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a69ae758-eca6-4478-8349-365ea5b348a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4806"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ø–æ–∫–∞ —á—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥ –æ —Ç–æ–º, —á—Ç–æ –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª-–≤–æ–º –æ–±—Ä–∞–∑—Ü–æ–≤ roc_auc –≤—ã—à–µ (–Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ —á—Ç–æ accuracy –º–µ–Ω—å—à–µ)  \n",
    "# —Å—Ç–æ–∏—Ç –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —É–≤–µ–ª–∏—á–∏—Ç—å –≤—ã–±–æ—Ä–∫—É, –Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –µ–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π\n",
    "\n",
    "# –æ–±—â–µ–µ –∫–æ–ª-–≤–æ —Å—Ç—Ä–æ–∫ –∫–ª–∞—Å—Å–∞ 1\n",
    "max_len = len(train_df[train_df['target'] == 1])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "caf6220f-7ef6-4df1-8e22-857ab92490ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>make sure alex know birthday fifteen minut far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>resum john lavorato thank vinc get move right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>733</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>overview hr associ analyst project per david r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>url url date not supplied government employees...</td>\n",
       "      <td>156</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>url url date suppli govern employe routin scre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>looks like your ham corpus by and large has to...</td>\n",
       "      <td>419</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>look like ham corpu larg jeremi url header spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9607</th>\n",
       "      <td>spam</td>\n",
       "      <td>your e mail to anvasetc 1111 groups msn com ca...</td>\n",
       "      <td>429</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>e mail anvasetc 1111 group msn com deliv sent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9608</th>\n",
       "      <td>spam</td>\n",
       "      <td>rs 250 for dental services worth rs 2150 denta...</td>\n",
       "      <td>130</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rs 250 dental servic worth rs 2150 dental spa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9609</th>\n",
       "      <td>spam</td>\n",
       "      <td>dost i am playing cricket knifeup pool etc and...</td>\n",
       "      <td>196</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dost play cricket knifeup pool etc win cash da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9610</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>interest binari option trade may continu infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9611</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>454</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dirti pictureblyk aircel thank valu member her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9612 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_type                                               text  \\\n",
       "0          ham  make sure alex knows his birthday is over in f...   \n",
       "1          ham  a resume for john lavorato thanks vince i will...   \n",
       "2          ham  overview of hr associates analyst project per ...   \n",
       "3          ham  url url date not supplied government employees...   \n",
       "4          ham  looks like your ham corpus by and large has to...   \n",
       "...        ...                                                ...   \n",
       "9607      spam  your e mail to anvasetc 1111 groups msn com ca...   \n",
       "9608      spam  rs 250 for dental services worth rs 2150 denta...   \n",
       "9609      spam  dost i am playing cricket knifeup pool etc and...   \n",
       "9610      spam  if you are interested in binary options tradin...   \n",
       "9611      spam  dirty pictureblyk on aircel thanks you for bei...   \n",
       "\n",
       "      num_characters  num_words  num_sentence  target  \\\n",
       "0                 86         16             1       0   \n",
       "1                520         97             1       0   \n",
       "2                733        127             1       0   \n",
       "3                156         26             1       0   \n",
       "4                419         85             1       0   \n",
       "...              ...        ...           ...     ...   \n",
       "9607             429         87             1       1   \n",
       "9608             130         24             1       1   \n",
       "9609             196         38             2       1   \n",
       "9610             114         18             1       1   \n",
       "9611             454         74             1       1   \n",
       "\n",
       "                                       transformed_text  \n",
       "0     make sure alex know birthday fifteen minut far...  \n",
       "1     resum john lavorato thank vinc get move right ...  \n",
       "2     overview hr associ analyst project per david r...  \n",
       "3     url url date suppli govern employe routin scre...  \n",
       "4     look like ham corpu larg jeremi url header spa...  \n",
       "...                                                 ...  \n",
       "9607  e mail anvasetc 1111 group msn com deliv sent ...  \n",
       "9608  rs 250 dental servic worth rs 2150 dental spa ...  \n",
       "9609  dost play cricket knifeup pool etc win cash da...  \n",
       "9610  interest binari option trade may continu infor...  \n",
       "9611  dirti pictureblyk aircel thank valu member her...  \n",
       "\n",
       "[9612 rows x 7 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –≤–æ–∑—å–º–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "df_class_0 = train_df[train_df['target'] == 0][:max_len]\n",
    "df_class_1 = train_df[train_df['target'] == 1][:max_len]\n",
    "\n",
    "train_df_2 = pd.concat([df_class_0, df_class_1], ignore_index=True)\n",
    "train_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "586be22e-4391-40fd-ae4f-b854b6d397a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç\n",
    "X = tfid.fit_transform(train_df_2['transformed_text']).toarray()\n",
    "y = train_df_2['target'].values\n",
    "\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4f474c4a-a696-4c80-be84-a2633a30ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.9121164846593863\n",
      "Precision:  0.9290393013100436\n",
      "Roc_auc:  0.9119753580546061\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.642225689027561\n",
      "Precision:  0.9651567944250871\n",
      "Roc_auc:  0.6398608887542728\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.8881955278211129\n",
      "Precision:  0.8592233009708737\n",
      "Roc_auc:  0.888454091125438\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.6640665626625065\n",
      "Precision:  0.5979708306911858\n",
      "Roc_auc:  0.6662379386439359\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.8975559022360895\n",
      "Precision:  0.9155701754385965\n",
      "Roc_auc:  0.8974000475963826\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.9235569422776911\n",
      "Precision:  0.9400871459694989\n",
      "Roc_auc:  0.9234233698238934\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.84399375975039\n",
      "Precision:  0.8857479387514723\n",
      "Roc_auc:  0.8436139717017871\n",
      "\n",
      "For:  Bgc\n",
      "Accuracy:  0.8965158606344253\n",
      "Precision:  0.8913043478260869\n",
      "Roc_auc:  0.8965498031240535\n",
      "\n",
      "For:  ETC\n",
      "Accuracy:  0.9209568382735309\n",
      "Precision:  0.9195402298850575\n",
      "Roc_auc:  0.9209602570204665\n",
      "\n",
      "For:  GBDT\n",
      "Accuracy:  0.8289131565262611\n",
      "Precision:  0.9151193633952255\n",
      "Roc_auc:  0.8281986932629484\n",
      "\n",
      "For:  xgb\n",
      "Accuracy:  0.890795631825273\n",
      "Precision:  0.9296424452133795\n",
      "Roc_auc:  0.8904812643330016\n"
     ]
    }
   ],
   "source": [
    "# –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "roc_auc_scores = []\n",
    "for name, clf in clfs.items():\n",
    "    current_accuracy, current_precision, current_roc_auc = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    print(\"Roc_auc: \", current_roc_auc)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "    roc_auc_scores.append(current_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaccce5-c68d-4987-9e0b-e26ee3372d16",
   "metadata": {},
   "source": [
    "### 4. –î–æ–æ–±—É—á–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41578fec-78f9-4498-966e-35835c7a5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤—ã–±—Ä–∞–Ω—ã –º–æ–¥–µ–ª–∏ - ETC, RF, SVC\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# –°–ª–æ–≤–∞—Ä—å —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏\n",
    "clfs = {\n",
    "    'ETC': ExtraTreesClassifier(random_state=42),\n",
    "    'RF': RandomForestClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã \n",
    "param_grid = {\n",
    "    'ETC': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 4, 6]\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n",
    "\n",
    "# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "best_models = {}\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Å–∫–æ—Ä–µ—Ä–∞\n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "# –¶–∏–∫–ª –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º\n",
    "for name, clf in clfs.items():\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid[name], scoring=scorers, refit='roc_auc', n_jobs=-1, cv=3, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    \n",
    "    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è {name}: {grid_search.best_params_}\")\n",
    "    y_pred = best_models[name].predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f91bf-e37f-4f5b-9267-b8195c4da11e",
   "metadata": {},
   "source": [
    "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è ETC: {'max_features': 'log2', 'min_samples_split': 6, 'n_estimators': 200}  #2\n",
    "Accuracy: 0.9318772750910036\n",
    "Precision: 0.9291666666666667\n",
    "ROC AUC: 0.931891739864134\n",
    "\n",
    "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è RF: {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 100}\n",
    "Accuracy: 0.9162766510660426\n",
    "Precision: 0.9241452991452992\n",
    "ROC AUC: 0.9162060274328242\n",
    "\n",
    "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è SVC: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "Accuracy: 0.9334373374934998\n",
    "Precision: 0.9431939978563773\n",
    "ROC AUC: 0.9333569512353426"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665aa4db-5dc0-43fb-aa90-b428a581e03f",
   "metadata": {},
   "source": [
    "### 5. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cacbbf13-a1bb-4683-b5de-af4c9adc9310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9360374414976599\n",
      "Precision: 0.9378947368421052\n",
      "ROC AUC: 0.9360169399852883\n"
     ]
    }
   ],
   "source": [
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏\n",
    "classifiers = [\n",
    "    ('rf', ExtraTreesClassifier(n_estimators=200, max_features='log2', min_samples_split=6, random_state=42)),\n",
    "    ('etc', RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_depth=None, random_state=42)),\n",
    "    ('svc', SVC(C=10, gamma='scale', kernel='rbf', random_state=42))\n",
    "]\n",
    "\n",
    "# –ú–µ—Ç–∞-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "meta_classifier = LogisticRegression()\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–µ–∫–∏–Ω–≥-–º–æ–¥–µ–ª–∏\n",
    "stacking_model = StackingClassifier(estimators=classifiers, final_estimator=meta_classifier, cv=5)\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ —Å—Ç–µ–∫–∏–Ω–≥-–º–æ–¥–µ–ª–∏\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dbd2af-c6af-4f2f-89af-144a8efb9118",
   "metadata": {},
   "source": [
    "### 6. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–æ–π –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ transformer https://huggingface.co/mshenoda/roberta-spam?text=delivery+status+notification+failure+the+following+message+to+was+undeliverable+the+reason+for+the+problem+5+1+0+unknown+address+error+550+5+1+1+unknown+or+illegal+alias+gkoppmal+elp+rr+com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f0d22933-858a-401d-9627-f48cf198065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mshenoda/roberta-spam\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mshenoda/roberta-spam\")\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts.iloc[idx]\n",
    "\n",
    "# C–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "texts = train_df['text'][:1000]\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "dataset = TextDataset(texts)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ DataLoader –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞—Ç—á–∞–º–∏\n",
    "loader = DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–µ–π\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    for batch in dataloader:\n",
    "        texts = batch\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            probabilities.extend(probs.tolist())\n",
    "            predictions.extend(preds.tolist())\n",
    "    return probabilities, predictions\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "probabilities, predictions = predict(model, loader)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6e06530c-9825-4beb-a083-9d6aea444a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.998\n",
      "Precision: 0.9965986394557823\n",
      "ROC AUC: 0.9975911044304407\n"
     ]
    }
   ],
   "source": [
    "# –∏–∑–º–µ—Ä–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "y_test = train_df['target'][:1000]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "print(f\"Precision: {precision_score(y_test, predictions)}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378ff41-6afb-4555-9dbe-b2bc127023b0",
   "metadata": {},
   "source": [
    "### 7. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9ba88927-ade0-4341-88ad-f28eb6dd87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j jim whitehead ejw cse ucsc edu writes j you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original message from bitbitch magnesium net p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java for managers vince durasoft who just taug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a youtuber name saiman says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>underpriced issue with high return on equity t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>husband to wifetum meri zindagi hoorwifeor kya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>baylor enron case study cindy yes i shall co a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>boring as compared to tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>hellogorgeous hows u my fone was on charge lst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>energy conference mark we are really swamped a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     j jim whitehead ejw cse ucsc edu writes j you ...\n",
       "1     original message from bitbitch magnesium net p...\n",
       "2     java for managers vince durasoft who just taug...\n",
       "3                  there is a youtuber name saiman says\n",
       "4     underpriced issue with high return on equity t...\n",
       "...                                                 ...\n",
       "4065  husband to wifetum meri zindagi hoorwifeor kya...\n",
       "4066  baylor enron case study cindy yes i shall co a...\n",
       "4067                           boring as compared to tp\n",
       "4068  hellogorgeous hows u my fone was on charge lst...\n",
       "4069  energy conference mark we are really swamped a...\n",
       "\n",
       "[4070 rows x 1 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_spam.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3c598608-2e88-4338-b18f-98f644b333eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9d450ea1-85bb-463f-acc4-e2f362d9996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "texts = test_df['text']\n",
    "\n",
    "dataset = TextDataset(texts)\n",
    "loader = DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–µ–π\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        print(f'Batch {idx}')\n",
    "        texts = batch\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            probabilities.extend(probs.tolist())\n",
    "            predictions.extend(preds.tolist())\n",
    "    return probabilities, predictions\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "probabilities, predictions = predict(model, loader)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "90ea957e-10d1-42b7-9b56-b6e68e191917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ñ-—è –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–∞ –≤ ham/spam\n",
    "def decode_prediction(class_prediction):\n",
    "    if class_prediction == 0:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'spam'\n",
    "\n",
    "test_df['class_prediction'] = predictions\n",
    "test_df['score'] = test_df['class_prediction'].apply(decode_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fafbbe8b-7fb1-4774-b290-3aec5d3b173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –º–æ–¥–µ–ª–∏\n",
    "test_df[['score', 'text']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
